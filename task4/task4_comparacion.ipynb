{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba9ae41",
   "metadata": {},
   "source": [
    "# Carga de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f193c771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datos divididos: 9144 train (80%), 2286 test (20%)\n",
      "Datos listos para Task 4.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import warnings\n",
    "# Importamos las herramientas de limpieza del Task 2 \n",
    "sys.path.append('../task2') \n",
    "from data_loading import limpiar_datos\n",
    "from feature_selection import seleccionar_features\n",
    "from data_scaling import escalar_datos\n",
    "from data_splitting import dividir_datos\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargar y preparar los mismos datos que en Task 3\n",
    "df_clean = limpiar_datos('../task2/dataset_phishing.csv')\n",
    "top_2_features, X_all, y = seleccionar_features(df_clean, n_features=2)\n",
    "\n",
    "X_2d = df_clean[top_2_features]\n",
    "X_2d_scaled, scaler_2d = escalar_datos(X_2d, y, method='standard')\n",
    "X_train, X_test, y_train, y_test = dividir_datos(X_2d_scaled, y)\n",
    "\n",
    "# Convertir a numpy para evitar warnings de sklearn\n",
    "X_train_np = X_train.values\n",
    "y_train_np = y_train.values\n",
    "X_test_np = X_test.values\n",
    "y_test_np = y_test.values\n",
    "\n",
    "print(\"Datos listos para Task 4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88cafda",
   "metadata": {},
   "source": [
    "# Implementación con Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992ebd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelos de Scikit-Learn entrenados exitosamente.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# --- 1. Regresión Logística (Sklearn) ---\n",
    "sk_log_model = LogisticRegression(random_state=42)\n",
    "sk_log_model.fit(X_train_np, y_train_np)\n",
    "y_pred_sk_log = sk_log_model.predict(X_test_np)\n",
    "\n",
    "# --- 2. K-Nearest Neighbors (Sklearn) ---\n",
    "# Usamos k=3\n",
    "sk_knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "sk_knn_model.fit(X_train_np, y_train_np)\n",
    "y_pred_sk_knn = sk_knn_model.predict(X_test_np)\n",
    "\n",
    "print(\"Modelos de Scikit-Learn entrenados exitosamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3462f28",
   "metadata": {},
   "source": [
    "# Tabla Comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fac082e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tabla Comparativa Final ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manual - Regresión Logística</td>\n",
       "      <td>0.866100</td>\n",
       "      <td>0.872700</td>\n",
       "      <td>0.857400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manual - KNN (k=3)</td>\n",
       "      <td>0.500900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sklearn - Regresión Logística</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.872663</td>\n",
       "      <td>0.857393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sklearn - KNN (k=3)</td>\n",
       "      <td>0.500875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Modelo  Accuracy  Precision    Recall\n",
       "0   Manual - Regresión Logística  0.866100   0.872700  0.857400\n",
       "1             Manual - KNN (k=3)  0.500900   1.000000  0.001700\n",
       "2  Sklearn - Regresión Logística  0.866142   0.872663  0.857393\n",
       "3            Sklearn - KNN (k=3)  0.500875   1.000000  0.001750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Función auxiliar para calcular métricas\n",
    "def get_metrics(y_true, y_pred, model_name):\n",
    "    return {\n",
    "        'Modelo': model_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "\n",
    "# Resultados Manuales (Extraídos de Task 3) ---\n",
    "\n",
    "# 1. Regresión Logística Manual\n",
    "metrics_list.append({\n",
    "    'Modelo': 'Manual - Regresión Logística',\n",
    "    'Accuracy': 0.8661,   # Valor de tu output celda 15\n",
    "    'Precision': 0.8727,  # Calculado: 980 / 1123\n",
    "    'Recall': 0.8574      # Calculado: 980 / 1143\n",
    "})\n",
    "\n",
    "# 2. KNN Manual (k=3)\n",
    "metrics_list.append({\n",
    "    'Modelo': 'Manual - KNN (k=3)',\n",
    "    'Accuracy': 0.5009,   # Valor de tu output celda 23\n",
    "    'Precision': 1.0,     # Calculado: 2 / 2 (Pocos positivos, pero todos correctos)\n",
    "    'Recall': 0.0017      # Calculado: 2 / 1143 (Detectó muy pocos ataques)\n",
    "})\n",
    "\n",
    "# --- Resultados Sklearn (Calculados en este notebook) ---\n",
    "metrics_list.append(get_metrics(y_test_np, y_pred_sk_log, 'Sklearn - Regresión Logística'))\n",
    "metrics_list.append(get_metrics(y_test_np, y_pred_sk_knn, 'Sklearn - KNN (k=3)'))\n",
    "\n",
    "# Crear DataFrame y mostrar\n",
    "comparison_df = pd.DataFrame(metrics_list)\n",
    "print(\"\\n=== Tabla Comparativa Final ===\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b934ce",
   "metadata": {},
   "source": [
    "## 2. Análisis de Cierre\n",
    "\n",
    "### a. ¿Cuál implementación fue mejor y por qué cree que sucedió?\n",
    "\n",
    "Se observó que la implementación manual de Regresión Logística obtuvo una exactitud de 86.61%, prácticamente idéntica a la de Scikit-Learn. Esto valida la corrección de las fórmulas matemáticas aplicadas. Sin embargo, se prefiere el uso de Scikit-Learn en producción por su eficiencia computacional y facilidad de implementación y estas diferencias clave:\n",
    "\n",
    "1.  **Optimizaciones:** Sklearn no utiliza un descenso de gradiente simple. Implementa solucionadores avanzados como `lbfgs` o `liblinear` que ajustan el *learning rate* dinámicamente, logrando converger más rápido.\n",
    "\n",
    "2.  **Estructuras de Datos:** Para KNN, nuestra implementación manual calcula la distancia contra todos los puntos. Sklearn utiliza estructuras de árbol KD-Trees o Ball-Trees que reducen la complejidad de búsqueda  haciendo el proceso mucho más veloz.\n",
    "\n",
    "### b. Phishing: Falsos Positivos vs. Falsos Negativos\n",
    "\n",
    "**Conclusión:** El error más costoso es el **Falso Negativo** por lo tanto, la métrica que deberíamos priorizar es el **Recall (Sensibilidad)**. Buscamos maximizar la detección de amenazas reales, incluso si eso implica tolerar una tasa ligeramente mayor de falsas alarmas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
